{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc, delta\n",
    "from scipy import signal\n",
    "import re\n",
    "\n",
    "# 读取已经用 HTK 计算好的 MFCC 特征\n",
    "RATE = 16000\n",
    "\n",
    "\n",
    "def extract_MFCC(audio):\n",
    "    wav_feature = mfcc(audio, samplerate=RATE, numcep=13, winlen=0.025, winstep=0.01, nfilt=26, nfft=512, lowfreq=0,\n",
    "                       highfreq=None, preemph=0.97)\n",
    "    d_mfcc_feat = delta(wav_feature, 1)\n",
    "    d_mfcc_feat2 = delta(wav_feature, 2)\n",
    "    feature_mfcc = np.hstack((wav_feature, d_mfcc_feat, d_mfcc_feat2))\n",
    "    return feature_mfcc\n",
    "\n",
    "\n",
    "# extract_MFCC(myrecording2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from Utils.record import record_once\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write, read\n",
    "\n",
    "sos = signal.butter(99, [2 * 250, 2 * 3e3], fs=RATE, output='sos', btype='bandpass')\n",
    "\n",
    "\n",
    "def bandpass(wav_data, order, fre_c):\n",
    "    filtedData = signal.sosfilt(sos, wav_data)  # data为要过滤的信号\n",
    "    # return np.reshape(filtedData, (len(filtedData), 1))\n",
    "    return filtedData\n",
    "\n",
    "# myrecording = record_once(1, RATE, 3, 'one', 'test_data')\n",
    "\n",
    "# myrecording2 = bandpass(myrecording, 99, 3e3)\n",
    "# sd.play(myrecording2, samplerate=RATE)\n",
    "# sd.wait()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "###\n",
    "# sos = signal.butter(99, [2*250, 2 * 3e3], fs=RATE, output='sos', btype='bandpass')\n",
    "fs, myrecording = read(\n",
    "    r\"D:\\Program\\pyProject\\speech_signal_processing\\ThirdPartyRepos\\MFCC\\test_data\\one_1669015379.wav\")\n",
    "# myrecording2 = signal.sosfilt(sos, myrecording.ravel())  # data为要过滤的信号\n",
    "myrecording2 = bandpass(myrecording, 99, 3e3)\n",
    "sd.play(myrecording2, samplerate=RATE)\n",
    "sd.wait()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getMFCC(datapath):\n",
    "    labels = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "    MFCC = []\n",
    "    files = os.listdir(datapath)  # 得到文件夹下的所有文件名称\n",
    "    rule = re.compile(r'(.*?)_.*?')\n",
    "    for i in range(10):\n",
    "        MFCC_rows = []\n",
    "        for file in files:  # 遍历文件夹\n",
    "            label = re.findall(rule, str(file))\n",
    "            label = ''.join(label)\n",
    "            if label == labels[i]:\n",
    "                file_name = os.path.join(datapath, file)\n",
    "                fs, audio = wav.read(file_name)  # audio: (len, )\n",
    "                feature = extract_MFCC(bandpass(audio, 99, 3e3))\n",
    "                MFCC_rows.append(feature)\n",
    "        MFCC.append(MFCC_rows)\n",
    "    return MFCC\n",
    "\n",
    "\n",
    "_datapath = r\"D:\\Program\\pyProject\\DSP_SpeechNumberRecognization\\dataset_test\"\n",
    "_MFCC = getMFCC(_datapath)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def getMFCC_train(datapath):\n",
    "    labels = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "    MFCC = []\n",
    "    for i in labels:\n",
    "        MFCC_rows = []\n",
    "        path = os.path.join(datapath, i)\n",
    "        # print(path)\n",
    "        for file in os.listdir(path):  # 遍历文件夹\n",
    "            file_name = os.path.join(datapath, i, file)\n",
    "            fs, audio = wav.read(file_name)  # audio: (len, )\n",
    "            feature = extract_MFCC(bandpass(audio, 99, 3e3))\n",
    "            MFCC_rows.append(feature)\n",
    "        MFCC.append(MFCC_rows)\n",
    "    return MFCC\n",
    "\n",
    "\n",
    "_datapath = r\"D:\\Program\\pyProject\\DSP_SpeechNumberRecognization\\dataset\"\n",
    "_MFCC = getMFCC_train(_datapath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "\n",
    "# DTW 算法...\n",
    "def dtw(M1, M2):\n",
    "    # 初始化数组 大小为 M1 * M2\n",
    "    M1_len = len(M1)\n",
    "    M2_len = len(M2)\n",
    "    cost = [[0 for i in range(M2_len)] for j in range(M1_len)]\n",
    "\n",
    "    # 初始化 dis 数组\n",
    "    dis = []\n",
    "    for i in range(M1_len):\n",
    "        dis_row = []\n",
    "        for j in range(M2_len):\n",
    "            dis_row.append(distance(M1[i], M2[j]))\n",
    "        dis.append(dis_row)\n",
    "\n",
    "    # 初始化 cost 的第 0 行和第 0 列\n",
    "    cost[0][0] = dis[0][0]\n",
    "    for i in range(1, M1_len):\n",
    "        cost[i][0] = cost[i - 1][0] + dis[i][0]\n",
    "    for j in range(1, M2_len):\n",
    "        cost[0][j] = cost[0][j - 1] + dis[0][j]\n",
    "\n",
    "    # 开始动态规划\n",
    "    for i in range(1, M1_len):\n",
    "        for j in range(1, M2_len):\n",
    "            cost[i][j] = min(cost[i - 1][j] + dis[i][j] * 1, cost[i - 1][j - 1] + dis[i][j] * 2,\n",
    "                             cost[i][j - 1] + dis[i][j] * 1)\n",
    "    return cost[M1_len - 1][M2_len - 1]\n",
    "\n",
    "\n",
    "# 两个维数相等的向量之间的距离\n",
    "def distance(x1, x2):\n",
    "    sum = 0\n",
    "    for i in range(len(x1)):\n",
    "        sum = sum + abs(x1[i] - x2[i])\n",
    "    return sum\n",
    "\n",
    "\n",
    "def train_model(path):\n",
    "    # 存储所有语音文件的 MFCC 特征\n",
    "    # 读取已经用 HTK 计算好的 MFCC 特征\n",
    "    MFCC = getMFCC(path)\n",
    "    return MFCC\n",
    "\n",
    "\n",
    "def speech_recognition(MFCC_models, wave_data):\n",
    "    MFCC_recorded = extract_MFCC(wave_data)\n",
    "\n",
    "    # 进行匹配\n",
    "    flag = 0\n",
    "    # min_dis = dtw(MFCC_recorded, MFCC_models[0][0])\n",
    "    min_dis = 0xffffff\n",
    "    for j in range(0, len(MFCC_models)):\n",
    "        diss = []\n",
    "        for mfcc_i in MFCC_models[j][:10]:\n",
    "            dis = dtw(MFCC_recorded, mfcc_i)\n",
    "            diss.append(dis)\n",
    "        dis = np.mean(diss)\n",
    "        # print(diss)\n",
    "        if dis < min_dis:\n",
    "            min_dis = dis\n",
    "            flag = j\n",
    "    return flag"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_79741.wav <-> 4\n",
      "one_54027.wav <-> 7\n",
      "one_77038.wav <-> 2\n",
      "two_39242.wav <-> 4\n",
      "two_47047.wav <-> 2\n",
      "three_35168.wav <-> 2\n",
      "three_45407.wav <-> 9\n",
      "three_77900.wav <-> 4\n",
      "four_17868.wav <-> 2\n",
      "four_59485.wav <-> 9\n",
      "five_71840.wav <-> 9\n",
      "five_85869.wav <-> 4\n",
      "five_86674.wav <-> 2\n",
      "six_98475.wav <-> 2\n",
      "six_99035.wav <-> 2\n",
      "seven_69828.wav <-> 1\n",
      "seven_77171.wav <-> 2\n",
      "seven_91891.wav <-> 9\n",
      "eight_18128.wav <-> 2\n",
      "eight_80167.wav <-> 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19420/1792993362.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     46\u001B[0m                 \u001B[0maudio\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_longest_chunk\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{file} <-> {speech_recognition(_MFCC, bandpass(audio, 99, 3e3))}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m \u001B[0mmfcc_test\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mr\"D:\\Program\\pyProject\\DSP_SpeechNumberRecognization\\dataset_test\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     49\u001B[0m \u001B[1;31m# print(speech_recognition(_MFCC, myrecording2))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19420/1792993362.py\u001B[0m in \u001B[0;36mmfcc_test\u001B[1;34m(datapath)\u001B[0m\n\u001B[0;32m     45\u001B[0m                 \u001B[0mfile_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdatapath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m                 \u001B[0maudio\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_longest_chunk\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m                 \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{file} <-> {speech_recognition(_MFCC, bandpass(audio, 99, 3e3))}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m \u001B[0mmfcc_test\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mr\"D:\\Program\\pyProject\\DSP_SpeechNumberRecognization\\dataset_test\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;31m# print(speech_recognition(_MFCC, myrecording2))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19420/3376664404.py\u001B[0m in \u001B[0;36mspeech_recognition\u001B[1;34m(MFCC_models, wave_data)\u001B[0m\n\u001B[0;32m     55\u001B[0m         \u001B[0mdiss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmfcc_i\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mMFCC_models\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 57\u001B[1;33m             \u001B[0mdis\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdtw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mMFCC_recorded\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmfcc_i\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     58\u001B[0m             \u001B[0mdiss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[0mdis\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdiss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19420/3376664404.py\u001B[0m in \u001B[0;36mdtw\u001B[1;34m(M1, M2)\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0mdis_row\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mM2_len\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m             \u001B[0mdis_row\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdistance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mM1\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mM2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m         \u001B[0mdis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdis_row\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19420/3376664404.py\u001B[0m in \u001B[0;36mdistance\u001B[1;34m(x1, x2)\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[0msum\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 35\u001B[1;33m         \u001B[0msum\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msum\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mabs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx1\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mx2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     36\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0msum\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import sounddevice as sd\n",
    "\n",
    "\n",
    "def get_nparray(audiosegment):\n",
    "    samples = audiosegment.get_array_of_samples()\n",
    "    samples_float = librosa.util.buf_to_float(samples, n_bytes=2, dtype=np.float32)\n",
    "    if audiosegment.channels == 2:\n",
    "        sample_left = np.copy(samples_float[::2])\n",
    "        sample_right = np.copy(samples_float[1::2])\n",
    "        sample_all = np.array([sample_left, sample_right])\n",
    "    else:\n",
    "        sample_all = samples_float\n",
    "\n",
    "    return sample_all\n",
    "\n",
    "\n",
    "def get_longest_chunk(path):\n",
    "    data = AudioSegment.from_wav(path)\n",
    "    # print(f\"db = {data.dBFS}\")\n",
    "    chunks = split_on_silence(data, min_silence_len=50, keep_silence=10, silence_thresh=data.dBFS - 5)\n",
    "    lid = 0\n",
    "    llen = 0\n",
    "    for i, _c in enumerate(chunks):\n",
    "        if len(_c) > llen:\n",
    "            llen = len(_c)\n",
    "            lid = i\n",
    "    return get_nparray(chunks[lid])\n",
    "\n",
    "\n",
    "# sd.play(get_nparray(data))\n",
    "\n",
    "def mfcc_test(datapath):\n",
    "    labels = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "    MFCC = []\n",
    "    files = os.listdir(datapath)  # 得到文件夹下的所有文件名称\n",
    "    for i in range(10):\n",
    "        for file in files:  # 遍历文件夹\n",
    "            rule = re.compile(r'(.*?)_.*?')\n",
    "            label = re.findall(rule, str(file))\n",
    "            label = ''.join(label)\n",
    "            if label == labels[i]:\n",
    "                file_name = os.path.join(datapath, file)\n",
    "                audio = get_longest_chunk(file_name)\n",
    "                print(f\"{file} <-> {speech_recognition(_MFCC, bandpass(audio, 99, 3e3))}\")\n",
    "\n",
    "\n",
    "mfcc_test(r\"D:\\Program\\pyProject\\DSP_SpeechNumberRecognization\\dataset_test\")\n",
    "# print(speech_recognition(_MFCC, myrecording2))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adaboost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "_MFCC_cleaned = []\n",
    "for digit, digits_mfcc in enumerate(_MFCC):\n",
    "    _MFCC_cleaned.append([])\n",
    "    for digit_mfcc in digits_mfcc:\n",
    "        if digit_mfcc.shape[0] == 99:  # 1s\n",
    "            _MFCC_cleaned[digit].append(digit_mfcc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "del _MFCC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "_MFCC_np = []\n",
    "_labels = []\n",
    "for digit, mfccs in enumerate(_MFCC_cleaned):\n",
    "    mfccs = np.dstack(mfccs).transpose(2, 0, 1)\n",
    "    l, m, n = mfccs.shape\n",
    "    mfccs = mfccs.reshape((l, m * n))\n",
    "    _MFCC_np.append(mfccs)\n",
    "    _labels.append(np.asarray([digit for i in range(len(mfccs))]))\n",
    "\n",
    "_MFCC_np = np.concatenate(_MFCC_np)\n",
    "_labels = np.concatenate(_labels)\n",
    "np.save(\"MFCC_np.npy\", _MFCC_np)\n",
    "np.save(\"labels.npy\", _labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(_MFCC_np, _labels, test_size=0.33, random_state=42)\n",
    "X_train_len, X_test_len = len(X_train), len(X_test)\n",
    "ratio = 0.7\n",
    "X_train = X_train[:int(X_train_len * ratio)]\n",
    "X_test = X_test[:int(X_test_len * ratio)]\n",
    "y_train = y_train[:int(X_train_len * ratio)]\n",
    "y_test = y_test[:int(X_test_len * ratio)]\n",
    "X_train_len, X_test_len = len(X_train), len(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "np.save(\"MFCC_np.npy\", _MFCC_np)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4928169893816365"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator=ExtraTreeClassifier(max_depth=13), n_estimators=600, random_state=233)\n",
    "\n",
    "abc.fit(X_train, y_train)\n",
    "abc.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'base_estimator': ExtraTreeClassifier(max_depth=10), 'n_estimators': 900}\n",
      "Best Train Score: 0.43822599893255293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Find Best parameter first\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "\n",
    "param_grid = {\"base_estimator\": [ExtraTreeClassifier(max_depth=i) for i in [10, 50, 100]],\n",
    "              \"n_estimators\": [300, 600, 900],\n",
    "              }\n",
    "grid_search = GridSearchCV(AdaBoostClassifier(random_state=233), param_grid, cv=5, n_jobs=8)\n",
    "\n",
    "# Fit Model\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Train Score: {grid_search.best_score_}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6574016239850093"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "svc.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'kernel': 'poly'}\n",
      "Best Train Score: 0.6317087351486381\n",
      "Test Score: 1.0 \n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"C\": [0.1, 1, 10],\n",
    "              \"kernel\": ['rbf', 'poly', 'rbf']}\n",
    "# grid_search = GridSearchCV(SVC(gamma='auto'), param_grid, cv=4, n_jobs=8)\n",
    "grid_search = GridSearchCV(SVC(gamma='scale'), param_grid, cv=4, n_jobs=8)\n",
    "\n",
    "# Fit Model\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Train Score: {grid_search.best_score_}\")\n",
    "\n",
    "score = grid_search.score(X_train, y_train)\n",
    "print(f\"Test Score: {score} \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.6718200983836964 \n"
     ]
    }
   ],
   "source": [
    "score = grid_search.score(X_test, y_test)\n",
    "print(f\"Test Score: {score} \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(99*39, 1000))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(1000, 1000))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(1000, 200))\n",
    "        self.layer4 = nn.Sequential(nn.Linear(200, 200))\n",
    "        self.layer5 = nn.Sequential(nn.Linear(200, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x) + x)\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        x = torch.relu(self.layer4(x) + x)\n",
    "        x = self.layer5(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "_model = mlp().float()#.cuda()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "class MfccData(Dataset):\n",
    "    def __len__(self):\n",
    "        return len(X_train)\n",
    "    def __getitem__(self, index):\n",
    "        return X_train[index], y_train[index]\n",
    "\n",
    "bs = 1000\n",
    "batch = 0\n",
    "\n",
    "_loss_fn = nn.CrossEntropyLoss()\n",
    "_optimizer = torch.optim.SGD(_model.parameters(), lr=1e-3)\n",
    "\n",
    "_mfcc_data = DataLoader(MfccData(), batch_size=bs, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "def eval():\n",
    "    results = []\n",
    "    test_bs = 100\n",
    "    for _i in range(4):\n",
    "        _index = np.random.choice(range(X_test.shape[0]), replace=False, size=(test_bs,))\n",
    "        _X = torch.from_numpy(X_test[_index, :]).float()\n",
    "        _y = (torch.from_numpy(y_test[_index])).long()\n",
    "        out = _model(_X)\n",
    "        _,pred = out.max(1)\n",
    "        num_correct = (pred == _y).sum().item()\n",
    "        result = num_correct / _y.shape[0]\n",
    "        # print(result)   #64\n",
    "        results.append(result)\n",
    "    # print(f\"avg: {np.mean(results)}\")\n",
    "    return np.mean(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50, 0.9982843399047852 <-> 0.5475\n",
      "100, 1.0033979415893555 <-> 0.6125\n",
      "150, 0.8210480809211731 <-> 0.6325000000000001\n",
      "200, 0.7832427620887756 <-> 0.6225\n",
      "250, 0.8252797722816467 <-> 0.6275000000000001\n",
      "300, 0.8073787689208984 <-> 0.66\n",
      "350, 0.7030922770500183 <-> 0.6525\n",
      "400, 0.74298495054245 <-> 0.65\n",
      "450, 0.6984407305717468 <-> 0.685\n",
      "500, 0.656196117401123 <-> 0.635\n",
      "550, 0.621052622795105 <-> 0.6775\n",
      "600, 0.5951574444770813 <-> 0.6775\n",
      "650, 0.6119892597198486 <-> 0.6775\n",
      "700, 0.5497257709503174 <-> 0.705\n",
      "750, 0.5174782276153564 <-> 0.655\n",
      "800, 0.5516507625579834 <-> 0.7025\n",
      "850, 0.4545406997203827 <-> 0.6525\n",
      "900, 0.4911038279533386 <-> 0.6825000000000001\n",
      "950, 0.461279034614563 <-> 0.7224999999999999\n",
      "1000, 0.43532228469848633 <-> 0.675\n",
      "1050, 0.41458234190940857 <-> 0.68\n",
      "1100, 0.3481624126434326 <-> 0.6775\n",
      "1150, 0.4127042293548584 <-> 0.6925\n",
      "1200, 0.4236237108707428 <-> 0.71\n",
      "1250, 0.3664504587650299 <-> 0.73\n",
      "1300, 0.33918970823287964 <-> 0.675\n",
      "1350, 0.3182563781738281 <-> 0.67\n",
      "1400, 0.3372471332550049 <-> 0.7\n",
      "1450, 0.3050307333469391 <-> 0.7324999999999999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19420/3015606491.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m         \u001B[0m_X\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_X\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;31m#.cuda()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m         \u001B[0m_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_y\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;31m#.cuda()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m         \u001B[0mpred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_X\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_loss_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19420/3483399816.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program\\python37\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    137\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    138\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 139\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    140\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program\\python37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     95\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 96\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     97\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program\\python37\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mlinear\u001B[1;34m(input, weight, bias)\u001B[0m\n\u001B[0;32m   1845\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhas_torch_function_variadic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1846\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1847\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1848\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1849\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    for b, (_X, _y) in enumerate(_mfcc_data):\n",
    "        _model.train()\n",
    "        _X = _X.float()#.cuda()\n",
    "        _y = _y.long()#.cuda()\n",
    "        pred = _model(_X)\n",
    "        loss = _loss_fn(pred, _y)\n",
    "\n",
    "        # BP\n",
    "        _optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        _optimizer.step()\n",
    "        batch += 1\n",
    "        if batch % 50 == 0:\n",
    "            _model.eval()\n",
    "            eval_score = eval()\n",
    "            print(f\"{batch}, {loss} <-> {eval_score}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 39)\n",
      "zero_79741.wav <-> tensor([2])\n",
      "(99, 39)\n",
      "one_54027.wav <-> tensor([1])\n",
      "(99, 39)\n",
      "zero_79741.wav <-> tensor([2])\n",
      "(99, 39)\n",
      "two_39242.wav <-> tensor([1])\n",
      "(99, 39)\n",
      "zero_79741.wav <-> tensor([2])\n",
      "(99, 39)\n",
      "three_35168.wav <-> tensor([2])\n",
      "(99, 39)\n",
      "four_17868.wav <-> tensor([1])\n",
      "(99, 39)\n",
      "zero_79741.wav <-> tensor([2])\n",
      "(99, 39)\n",
      "five_71840.wav <-> tensor([8])\n",
      "(99, 39)\n",
      "two_39242.wav <-> tensor([1])\n",
      "(99, 39)\n",
      "zero_79741.wav <-> tensor([2])\n",
      "(99, 39)\n",
      "six_98475.wav <-> tensor([8])\n",
      "(99, 39)\n",
      "zero_79741.wav <-> tensor([2])\n",
      "(99, 39)\n",
      "seven_69828.wav <-> tensor([8])\n",
      "(99, 39)\n",
      "zero_79741.wav <-> tensor([2])\n",
      "(99, 39)\n",
      "eight_18128.wav <-> tensor([2])\n",
      "(99, 39)\n",
      "one_54027.wav <-> tensor([1])\n",
      "(99, 39)\n",
      "zero_79741.wav <-> tensor([2])\n",
      "(99, 39)\n",
      "nine_83327.wav <-> tensor([1])\n",
      "(99, 39)\n",
      "zero_79741.wav <-> tensor([2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pydub.silence import detect_nonsilent\n",
    "def mfcc_test_mlp(datapath):\n",
    "    labels = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "    MFCC = []\n",
    "    files = os.listdir(datapath)  # 得到文件夹下的所有文件名称\n",
    "    for i in range(10):\n",
    "        for file in files:  # 遍历文件夹\n",
    "            rule = re.compile(r'(.*?)_.*?')\n",
    "            label = re.findall(rule, str(file))\n",
    "            label = ''.join(label)\n",
    "            if label == labels[i]:\n",
    "                file_name = os.path.join(datapath, file)\n",
    "                data = AudioSegment.from_wav(file_name)\n",
    "                # print(f\"db = {data.dBFS}\")\n",
    "                secs = detect_nonsilent(data, min_silence_len=50, silence_thresh=data.dBFS - 6)\n",
    "                max_len = 0\n",
    "                max_i = 0\n",
    "                for i, sec in enumerate(secs):\n",
    "                    sec_diff = sec[1] - sec[0]\n",
    "                    if sec_diff > max_len:\n",
    "                        max_len = sec_diff\n",
    "                        max_i = i\n",
    "                # 32000~199(200)~2000\n",
    "                # 16000~99(100)~1000\n",
    "                # sec_start, sec_end = int(secs[max_i][0] / 10), int(secs[max_i][0] / 10) + 99\n",
    "                sec_start, sec_end = int(secs[0][0] / 10), int(secs[0][0] / 10) + 99\n",
    "\n",
    "                fs, audio = wav.read(file_name)  # audio: (len, )\n",
    "                feature = extract_MFCC(bandpass(audio, 99, 3e3))[sec_start:sec_end, :]\n",
    "                import numpy as np\n",
    "\n",
    "                feature = np.pad(feature, ((0, 99 - feature.shape[0]), (0, 0)), mode='median')\n",
    "                print(feature.shape)\n",
    "                feature = feature.ravel().reshape((1, -1))\n",
    "                _X = torch.from_numpy(feature).float()\n",
    "                out = _model(_X)\n",
    "                _, pred = out.max(1)\n",
    "\n",
    "                print(f\"{file} <-> {pred}\")\n",
    "mfcc_test_mlp(r\"D:\\Program\\pyProject\\DSP_SpeechNumberRecognization\\dataset_test\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "from pydub.silence import detect_nonsilent\n",
    "data = AudioSegment.from_wav(test_file)\n",
    "# print(f\"db = {data.dBFS}\")\n",
    "secs = detect_nonsilent(data, min_silence_len=50, silence_thresh=data.dBFS - 6)\n",
    "max_len = 0\n",
    "max_i = 0\n",
    "for i, sec in enumerate(secs):\n",
    "    sec_diff = sec[1] - sec[0]\n",
    "    if sec_diff > max_len:\n",
    "        max_len = sec_diff\n",
    "        max_i = i\n",
    "# 32000~199(200)~2000\n",
    "# 16000~99(100)~1000\n",
    "# sec_start, sec_end = int(secs[max_i][0] / 10), int(secs[max_i][0] / 10) + 99\n",
    "sec_start, sec_end = int(secs[0][0] / 10), int(secs[0][0] / 10) + 99"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 39)\n",
      "tensor([[-6.5244, -1.3311, -0.6291, -3.0086, -7.1605, -8.0040, -8.8795, -6.5457,\n",
      "         -2.0606, -3.8243]], grad_fn=<LogSoftmaxBackward>) tensor([2])\n"
     ]
    }
   ],
   "source": [
    "test_file = r\"D:\\Program\\pyProject\\DSP_SpeechNumberRecognization\\dataset_test\\eight_18128.wav\"\n",
    "fs, audio = wav.read(test_file)  # audio: (len, )\n",
    "feature = extract_MFCC(bandpass(audio, 99, 3e3))[sec_start:sec_end, :]\n",
    "import numpy as np\n",
    "feature = np.pad(feature, ((0, 99-feature.shape[0]), (0, 0)), mode='median')\n",
    "print(feature.shape)\n",
    "feature = feature.ravel().reshape((1, -1))\n",
    "_X = torch.from_numpy(feature).float()\n",
    "out = _model(_X)\n",
    "_,pred = out.max(1)\n",
    "print(out, pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
