{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pretrain (no need to run)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc, delta\n",
    "from scipy import signal\n",
    "import re\n",
    "\n",
    "# 读取已经用 HTK 计算好的 MFCC 特征\n",
    "RATE = 16000\n",
    "\n",
    "\n",
    "def extract_MFCC(audio):\n",
    "    wav_feature = mfcc(audio, samplerate=RATE, numcep=13, winlen=0.025, winstep=0.01, nfilt=26, nfft=512, lowfreq=0,\n",
    "                       highfreq=None, preemph=0.97)\n",
    "    d_mfcc_feat = delta(wav_feature, 1)\n",
    "    d_mfcc_feat2 = delta(wav_feature, 2)\n",
    "    feature_mfcc = np.hstack((wav_feature, d_mfcc_feat, d_mfcc_feat2))\n",
    "    return feature_mfcc\n",
    "\n",
    "\n",
    "sos = signal.butter(99, [2 * 250, 2 * 3e3], fs=RATE, output='sos', btype='bandpass')\n",
    "\n",
    "\n",
    "def bandpass(wav_data, order, fre_c):\n",
    "    filtedData = signal.sosfilt(sos, wav_data)  # data为要过滤的信号\n",
    "    # return np.reshape(filtedData, (len(filtedData), 1))\n",
    "    return filtedData\n",
    "\n",
    "\n",
    "def getMFCC_train(datapath):\n",
    "    labels = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "    MFCC = []\n",
    "    for i in labels:\n",
    "        MFCC_rows = []\n",
    "        path = os.path.join(datapath, i)\n",
    "        # print(path)\n",
    "        for file in os.listdir(path):  # 遍历文件夹\n",
    "            file_name = os.path.join(datapath, i, file)\n",
    "            fs, audio = wav.read(file_name)  # audio: (len, )\n",
    "            feature = extract_MFCC(bandpass(audio, 99, 3e3))\n",
    "            MFCC_rows.append(feature)\n",
    "        MFCC.append(MFCC_rows)\n",
    "    return MFCC\n",
    "\n",
    "\n",
    "_datapath = r\"D:\\Program\\pyProject\\DSP_SpeechNumberRecognization\\dataset\"\n",
    "_MFCC = getMFCC_train(_datapath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Pretrained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "_MFCC_np = np.load(\"MFCC_np.npy\")\n",
    "_labels = np.load(\"labels_np.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(_MFCC_np, _labels, test_size=0.33, random_state=42)\n",
    "X_train_len, X_test_len = len(X_train), len(X_test)\n",
    "ratio = 0.7\n",
    "X_train = X_train[:int(X_train_len * ratio)]\n",
    "X_test = X_test[:int(X_test_len * ratio)]\n",
    "y_train = y_train[:int(X_train_len * ratio)]\n",
    "y_test = y_test[:int(X_test_len * ratio)]\n",
    "X_train_len, X_test_len = len(X_train), len(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# sklearn\n",
    "## Adaboost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator=ExtraTreeClassifier(max_depth=13), n_estimators=600, random_state=233)\n",
    "\n",
    "abc.fit(X_train, y_train)\n",
    "abc.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Find Best parameter first\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "\n",
    "param_grid = {\"base_estimator\": [ExtraTreeClassifier(max_depth=i) for i in [10, 50, 100]],\n",
    "              \"n_estimators\": [300, 600, 900],\n",
    "              }\n",
    "grid_search = GridSearchCV(AdaBoostClassifier(random_state=233), param_grid, cv=5, n_jobs=8)\n",
    "\n",
    "# Fit Model\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Train Score: {grid_search.best_score_}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "svc.score(X_test, y_test)\n",
    "param_grid = {\"C\": [0.1, 1, 10],\n",
    "              \"kernel\": ['rbf', 'poly', 'rbf']}\n",
    "# grid_search = GridSearchCV(SVC(gamma='auto'), param_grid, cv=4, n_jobs=8)\n",
    "grid_search = GridSearchCV(SVC(gamma='scale'), param_grid, cv=4, n_jobs=8)\n",
    "\n",
    "# Fit Model\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Train Score: {grid_search.best_score_}\")\n",
    "\n",
    "score = grid_search.score(X_train, y_train)\n",
    "print(f\"Test Score: {score} \")\n",
    "score = grid_search.score(X_test, y_test)\n",
    "print(f\"Test Score: {score} \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(99 * 39, 1000))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(1000, 1000))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(1000, 200))\n",
    "        self.layer4 = nn.Sequential(nn.Linear(200, 200))\n",
    "        self.layer5 = nn.Sequential(nn.Linear(200, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x) + x)\n",
    "        x = torch.relu(self.layer3(x))\n",
    "        x = torch.relu(self.layer4(x) + x)\n",
    "        x = self.layer5(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "_model = mlp().float().cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Train Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/train')\n",
    "\n",
    "\n",
    "class MfccData(Dataset):\n",
    "    def __len__(self):\n",
    "        return len(X_train)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return X_train[index], y_train[index]\n",
    "\n",
    "\n",
    "bs = 1000\n",
    "batch = 0\n",
    "\n",
    "_loss_fn = nn.CrossEntropyLoss()\n",
    "_optimizer = torch.optim.AdamW(_model.parameters(), lr=1e-4)\n",
    "\n",
    "_mfcc_data = DataLoader(MfccData(), batch_size=bs, shuffle=True, num_workers=0)\n",
    "\n",
    "def to_cuda(*ts: torch.Tensor):\n",
    "    return [_ts.cuda() for _ts in ts]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def eval():\n",
    "    results = []\n",
    "    test_bs = 100\n",
    "    for _i in range(4):\n",
    "        _index = np.random.choice(range(X_test.shape[0]), replace=False, size=(test_bs,))\n",
    "        _X = torch.from_numpy(X_test[_index, :]).float()\n",
    "        _y = (torch.from_numpy(y_test[_index])).long()\n",
    "        _X, _y = to_cuda(_X, _y)\n",
    "        out = _model(_X)\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred == _y).sum().item()\n",
    "        result = num_correct / _y.shape[0]\n",
    "        # print(result)   #64\n",
    "        results.append(result)\n",
    "    # print(f\"avg: {np.mean(results)}\")\n",
    "    return np.mean(results)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "batch = 4000\n",
    "max_val_score = 0\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4050, 0.0616881288588047 <-> 0.77\n",
      "best model at 4050\n",
      "4100, 0.021399063989520073 <-> 0.72\n",
      "4150, 0.013324248604476452 <-> 0.7375\n",
      "4200, 0.009489394724369049 <-> 0.7550000000000001\n",
      "4250, 0.006943423766642809 <-> 0.7649999999999999\n",
      "4300, 0.005177389830350876 <-> 0.7725000000000001\n",
      "best model at 4300\n",
      "4350, 0.003626271616667509 <-> 0.7625\n",
      "4400, 0.0028443268965929747 <-> 0.7525\n",
      "4450, 0.0022522499784827232 <-> 0.73\n",
      "4500, 0.0018260566284880042 <-> 0.7325\n",
      "4550, 0.0013879138277843595 <-> 0.7375\n",
      "4600, 0.001220334437675774 <-> 0.7124999999999999\n",
      "4650, 0.0009969824459403753 <-> 0.7575\n",
      "4700, 0.000898712663911283 <-> 0.7675\n",
      "4750, 0.000696726085152477 <-> 0.7675000000000001\n",
      "4800, 0.0005596652626991272 <-> 0.7525\n",
      "4850, 0.000511816528160125 <-> 0.7725\n",
      "4900, 0.00044374517165124416 <-> 0.7475\n",
      "4950, 0.0003685857227537781 <-> 0.765\n",
      "5000, 0.0002890059258788824 <-> 0.7224999999999999\n",
      "5050, 0.00027758118812926114 <-> 0.7349999999999999\n",
      "5100, 0.00022532336879521608 <-> 0.7475\n",
      "5150, 0.00021757539070677012 <-> 0.77\n",
      "5200, 0.00018151877156924456 <-> 0.7575000000000001\n",
      "5250, 0.00014652473328169435 <-> 0.7675000000000001\n",
      "5300, 0.00014069373719394207 <-> 0.765\n",
      "5350, 0.0001231477945111692 <-> 0.7275\n",
      "5400, 0.00011395412002457306 <-> 0.74\n",
      "5450, 9.844519809121266e-05 <-> 0.7525\n",
      "5500, 9.159566252492368e-05 <-> 0.7825\n",
      "best model at 5500\n",
      "5550, 8.203873585443944e-05 <-> 0.71\n",
      "5600, 7.175507926149294e-05 <-> 0.7650000000000001\n",
      "5650, 6.150310218799859e-05 <-> 0.7525\n",
      "5700, 6.096006836742163e-05 <-> 0.8\n",
      "best model at 5700\n",
      "5750, 5.709602919523604e-05 <-> 0.7575000000000001\n",
      "5800, 5.034960850025527e-05 <-> 0.7725\n",
      "5850, 4.548035212792456e-05 <-> 0.755\n",
      "5900, 4.2192255932604894e-05 <-> 0.795\n",
      "5950, 3.764653956750408e-05 <-> 0.75\n",
      "6000, 3.6038960388395935e-05 <-> 0.7575000000000001\n",
      "6050, 3.137737439828925e-05 <-> 0.7575000000000001\n",
      "6100, 3.146497692796402e-05 <-> 0.7375\n",
      "6150, 2.7324900656822138e-05 <-> 0.74\n",
      "6200, 3.2025443942984566e-05 <-> 0.76\n",
      "6250, 2.467929880367592e-05 <-> 0.7625\n",
      "6300, 2.0618856069631875e-05 <-> 0.765\n",
      "6350, 2.2140919099911116e-05 <-> 0.7650000000000001\n",
      "6400, 1.8716287740971893e-05 <-> 0.7424999999999999\n",
      "6450, 1.8280637959833257e-05 <-> 0.745\n",
      "6500, 1.8044462194666266e-05 <-> 0.7725\n",
      "6550, 1.72503714566119e-05 <-> 0.7475\n",
      "6600, 1.5123335288080852e-05 <-> 0.7525\n",
      "6650, 1.3802357898384798e-05 <-> 0.7525\n",
      "6700, 1.3701485841011163e-05 <-> 0.72\n",
      "6750, 1.2241079275554512e-05 <-> 0.725\n",
      "6800, 1.08801614260301e-05 <-> 0.77\n",
      "6850, 9.970030987460632e-06 <-> 0.7575000000000001\n",
      "6900, 9.916367162077222e-06 <-> 0.7725\n",
      "6950, 8.841496310196817e-06 <-> 0.7275\n",
      "7000, 8.709072062629275e-06 <-> 0.7425\n",
      "7050, 8.512023669027258e-06 <-> 0.7625000000000001\n",
      "7100, 7.761849701637402e-06 <-> 0.745\n",
      "7150, 6.803081305406522e-06 <-> 0.7725\n",
      "7200, 6.8351541813171934e-06 <-> 0.74\n",
      "7250, 6.3217198658094276e-06 <-> 0.7525\n",
      "7300, 6.560691872437019e-06 <-> 0.7424999999999999\n",
      "7350, 5.530424459720962e-06 <-> 0.7650000000000001\n",
      "7400, 5.588715794146992e-06 <-> 0.75\n",
      "7450, 5.3565022426482756e-06 <-> 0.7325\n",
      "7500, 5.058966507931473e-06 <-> 0.7625000000000001\n",
      "7550, 4.688941771746613e-06 <-> 0.72\n",
      "7600, 4.760466708830791e-06 <-> 0.75\n",
      "7650, 4.284946044208482e-06 <-> 0.7175\n",
      "7700, 3.892511813319288e-06 <-> 0.76\n",
      "7750, 3.7410029563034186e-06 <-> 0.7525\n",
      "7800, 3.752684961000341e-06 <-> 0.7625000000000001\n",
      "7850, 4.0136997085937764e-06 <-> 0.7625000000000001\n",
      "7900, 3.1890697300696047e-06 <-> 0.7425\n",
      "7950, 3.082496732531581e-06 <-> 0.765\n",
      "8000, 2.902613687183475e-06 <-> 0.7\n",
      "8050, 3.039224338863278e-06 <-> 0.74\n",
      "8100, 2.9282418836373836e-06 <-> 0.7325\n",
      "8150, 2.5658507638581796e-06 <-> 0.7625\n",
      "8200, 2.5540473416185705e-06 <-> 0.7725000000000001\n",
      "8250, 2.38036136579467e-06 <-> 0.7625\n",
      "8300, 2.1269245280564064e-06 <-> 0.7575\n",
      "8350, 2.2687818272970617e-06 <-> 0.755\n",
      "8400, 2.2447461560659576e-06 <-> 0.7650000000000001\n",
      "8450, 2.0774527911271434e-06 <-> 0.7324999999999999\n",
      "8500, 2.02583396458067e-06 <-> 0.7825\n",
      "8550, 1.8632350702318945e-06 <-> 0.7825\n",
      "8600, 1.7238803593500052e-06 <-> 0.7375\n",
      "8650, 1.918905354614253e-06 <-> 0.7525\n",
      "8700, 1.6182614217541413e-06 <-> 0.715\n",
      "8750, 1.5455441371159395e-06 <-> 0.7174999999999999\n",
      "8800, 1.5311201195800095e-06 <-> 0.7424999999999999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "is_break = False\n",
    "while True:\n",
    "    if is_break:\n",
    "        break\n",
    "    for b, (_X, _y) in enumerate(_mfcc_data):\n",
    "        _model.train()\n",
    "        _X = _X.float()  #.cuda()\n",
    "        _y = _y.long()  #.cuda()\n",
    "        _X, _y = to_cuda(_X, _y)\n",
    "        pred = _model(_X)\n",
    "        loss = _loss_fn(pred, _y)\n",
    "\n",
    "        # BP\n",
    "        _optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        _optimizer.step()\n",
    "        batch += 1\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            _model.eval()\n",
    "            eval_score = eval()\n",
    "            print(f\"{batch}, {loss} <-> {eval_score}\")\n",
    "            writer.add_scalars('Training Loss',\n",
    "                               {'Train': loss, 'Val': eval_score},\n",
    "                               batch)\n",
    "            if eval_score > max_val_score:\n",
    "                torch.save(_model.state_dict(), f\"mlp-model-best.pth\")\n",
    "                print(f\"best model at {batch}\")\n",
    "                max_val_score = eval_score\n",
    "        if batch % 8800 == 0:\n",
    "            is_break = True\n",
    "            break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "torch.save(_model.state_dict(), f\"mlp-model-{batch}.pth\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## External Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from pydub.silence import detect_nonsilent\n",
    "\n",
    "\n",
    "def mfcc_test_mlp(datapath):\n",
    "    labels = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "    MFCC = []\n",
    "    files = os.listdir(datapath)  # 得到文件夹下的所有文件名称\n",
    "    for i in range(10):\n",
    "        for file in files:  # 遍历文件夹\n",
    "            rule = re.compile(r'(.*?)_.*?')\n",
    "            label = re.findall(rule, str(file))\n",
    "            label = ''.join(label)\n",
    "            if label == labels[i]:\n",
    "                file_name = os.path.join(datapath, file)\n",
    "                data = AudioSegment.from_wav(file_name)\n",
    "                # print(f\"db = {data.dBFS}\")\n",
    "                secs = detect_nonsilent(data, min_silence_len=50, silence_thresh=data.dBFS - 6)\n",
    "                max_len = 0\n",
    "                max_i = 0\n",
    "                for i, sec in enumerate(secs):\n",
    "                    sec_diff = sec[1] - sec[0]\n",
    "                    if sec_diff > max_len:\n",
    "                        max_len = sec_diff\n",
    "                        max_i = i\n",
    "                # 32000~199(200)~2000\n",
    "                # 16000~99(100)~1000\n",
    "                # sec_start, sec_end = int(secs[max_i][0] / 10), int(secs[max_i][0] / 10) + 99\n",
    "                sec_start, sec_end = int(secs[0][0] / 10), int(secs[0][0] / 10) + 99\n",
    "\n",
    "                fs, audio = wav.read(file_name)  # audio: (len, )\n",
    "                feature = extract_MFCC(bandpass(audio, 99, 3e3))[sec_start:sec_end, :]\n",
    "                import numpy as np\n",
    "\n",
    "                feature = np.pad(feature, ((0, 99 - feature.shape[0]), (0, 0)), mode='median')\n",
    "                print(feature.shape)\n",
    "                feature = feature.ravel().reshape((1, -1))\n",
    "                _X = torch.from_numpy(feature).float()\n",
    "                out = _model(_X)\n",
    "                _, pred = out.max(1)\n",
    "\n",
    "                print(f\"{file} <-> {pred}\")\n",
    "\n",
    "\n",
    "mfcc_test_mlp(r\"D:\\Program\\pyProject\\DSP_SpeechNumberRecognization\\dataset_test\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from pydub.silence import detect_nonsilent\n",
    "\n",
    "data = AudioSegment.from_wav(test_file)\n",
    "# print(f\"db = {data.dBFS}\")\n",
    "secs = detect_nonsilent(data, min_silence_len=50, silence_thresh=data.dBFS - 6)\n",
    "max_len = 0\n",
    "max_i = 0\n",
    "for i, sec in enumerate(secs):\n",
    "    sec_diff = sec[1] - sec[0]\n",
    "    if sec_diff > max_len:\n",
    "        max_len = sec_diff\n",
    "        max_i = i\n",
    "# 32000~199(200)~2000\n",
    "# 16000~99(100)~1000\n",
    "# sec_start, sec_end = int(secs[max_i][0] / 10), int(secs[max_i][0] / 10) + 99\n",
    "sec_start, sec_end = int(secs[0][0] / 10), int(secs[0][0] / 10) + 99\n",
    "test_file = r\"D:\\Program\\pyProject\\DSP_SpeechNumberRecognization\\dataset_test\\eight_18128.wav\"\n",
    "fs, audio = wav.read(test_file)  # audio: (len, )\n",
    "feature = extract_MFCC(bandpass(audio, 99, 3e3))[sec_start:sec_end, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "feature = np.pad(feature, ((0, 99 - feature.shape[0]), (0, 0)), mode='median')\n",
    "print(feature.shape)\n",
    "feature = feature.ravel().reshape((1, -1))\n",
    "_X = torch.from_numpy(feature).float()\n",
    "out = _model(_X)\n",
    "_, pred = out.max(1)\n",
    "print(out, pred)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
