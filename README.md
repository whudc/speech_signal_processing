# This project is the repo of our DSP big homework: Speech Digit Recognition
## Members:
Justin62628 whudc QH LD

## Development Log

### 研究目标

在不进行大规模数据采集的前提下，对组员语音数字信号进行识别率较高的识别。

- MFCC+DTW被玩烂了，不好玩，这个要在报告里提一嘴

### 预备知识

- 所有音频信号采样处理均在16kHz下完成

- **【创新点】**对于所有音频信号采样处理，我们设计了一个butterworth数字带通滤波器滤除人声以外的部分，提高了研究的科学规范性
- 模拟信号经数字采样后，声音可以由**“帧”**表示，每一帧可由若干采样点构成
- 所有测试数据均在TensorFlow的[开源数据](http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz)下获得

### 声音可由特征向量表示（一维表示）
- 对数字采样后的数字信号加窗处理可以获得声音每一帧的MFCC向量，其包括13个特征值，13个一阶差分特征值，13个二阶差分特征值，共39个**特征**

#### 机器学习方法处理特征
- 假设：每一个音素（0~9的中文、英文发音）可由符合某一分布的特征表示
- 可以通过使用SVM，Adaboost对音频的特征分类
- 音频特征的获取、处理方法：
  - 端点识别后（去除静音段，只取有发声者发声的部分），取长度为某个值的帧段（如99帧）获取MFCC，取平均值得到一个长度为39的向量进行机器学习特征分类
  - 端点识别后，取长度为某个值的帧段（如99帧）获取MFCC，将这些MFCC向量展平后得到一个长度为99x39的向量进行机器学习特征分类。该方法优于上者

- 结果分析：结果严重受噪音，端点识别起始点影响，准确率60%

#### MLP处理特征

- 对于上面的第二个方法，99x39的特征向量明显过大，设计使用五层的MLP神经网络进行相同特征的回归与预测，相当于对上面第二个方法的改进
- **【创新点】**设计使用了残差网络帮助网络收敛，其特点是容易优化,并且能够通过增加相当的深度来提高准确率。其内部的残差块使用了跳跃链接,缓解了在深度神经网络中增加深度带来了梯度消失的问题。
- 结果分析：结果仍然严重受噪音，端点识别起始点影响，准确率75%，实用价值不高

### 声音可由频谱表示（二维表示）

频谱中含有丰富的信息。对于一个二维频谱，显然可以将其作为图片处理

因此使用一个简单的CNN深度网络（这里可以使用resnet，imagenet等）对频谱进行处理

**【创新点】**：对比实验表明，加入了残差块可有效提高训练收敛速度

结果分析：

- 优点：对噪音鲁棒程度高，不受端点识别起始点影响，准确率85%+，实用价值较高
- 缺点：需要数据多，小数据样本训练极容易过拟合，训练难度大，不适用于大规模应用（可以让班级成员识别，但做不到全校成员的识别），CNN不具有一致性，对特定频谱存在偏好。

### 声音可被多种特征共同表示（高维表示）

由上我们可以总结出语音数字识别的几点共同难点：

- 特征维度要足够丰富 => 不要低维的MFCC，用高维的特征表示（这里要引入Word2Vec的概念）
- 特征维度不能使识别方法容易出现倾向性 =>
  - 多卷积，用多重卷积网络+无监督学习方法识别小样本特征 => Wav2Vec 1.0
  - 大数据样本预训练，将海量音频数据编码（前人的工作）为海量特征（甚至包括噪音的特征）+小数据样本Finetune，只使用我们需要的、能够识别语音数字信号的特征 => Wav2Vec 2.0

我们最后使用Wav2Vec 2

结果分析：对于任何人正确发音的语音数字信号，在噪音较小（<10dB）的环境下，准确率99%+
